{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhHukHgpFgxi",
        "outputId": "f6e3f88e-fa16-48be-c836-5144c5cd85e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "# TODO: check lr scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "9ALCt2-aGrI0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import cohen_kappa_score as kappa\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import time\n",
        "import pathlib\n",
        "\n",
        "# log folder to save log files\n",
        "log_folder = '/content/drive/MyDrive/asap/'\n",
        "\n",
        "# target column\n",
        "target_column = \"score\"\n",
        "\n",
        "# hyper parameters\n",
        "hp = {\n",
        "    \"base_model\": \"gpt2\",\n",
        "    \"lr\": 1e-4,\n",
        "    \"num_epochs\": 20,\n",
        "    \"batch_size\": 2,\n",
        "    \"use_amp\": True,\n",
        "    \"mixed_precision\": \"fp16\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5E6LL6CGlGU"
      },
      "source": [
        "# Prepare ASAP Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iI4gDr87GohH",
        "outputId": "5f31280c-27b7-4eda-95e3-4c92f28720e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   rater1  rater2  score  \n",
              "0       4       4      8  \n",
              "1       5       4      9  \n",
              "2       4       3      7  \n",
              "3       5       5     10  \n",
              "4       4       4      8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d90af5fc-208c-4da1-8364-735a32c963fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1</th>\n",
              "      <th>rater2</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d90af5fc-208c-4da1-8364-735a32c963fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d90af5fc-208c-4da1-8364-735a32c963fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d90af5fc-208c-4da1-8364-735a32c963fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7bf7eff4-273b-4fc0-8af0-f0cf73b0f99b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bf7eff4-273b-4fc0-8af0-f0cf73b0f99b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7bf7eff4-273b-4fc0-8af0-f0cf73b0f99b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Original kaggle training set\n",
        "kaggle_dataset  = pd.read_csv('/content/drive/MyDrive/asap-aes/training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
        "\n",
        "# Smaller training set used for this project\n",
        "dataset_df = pd.DataFrame(\n",
        "  {\n",
        "    'essay_id' : kaggle_dataset['essay_id'],\n",
        "    'essay_set' : kaggle_dataset['essay_set'],\n",
        "    'essay' : kaggle_dataset['essay'],\n",
        "    'rater1' : kaggle_dataset['rater1_domain1'],\n",
        "    'rater2' : kaggle_dataset['rater2_domain1'],\n",
        "    'score' : kaggle_dataset['domain1_score']\n",
        "  })\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OspK7Dll8nI",
        "outputId": "0d576778-1a7a-4b4f-fbb4-5b3fdfef52e9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTmNpJqfHY2R"
      },
      "source": [
        "## Use essay_set=1 for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il-xAB2lHVvq",
        "outputId": "abf8aef7-408f-43c2-e03f-76074686a25f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1783, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "essay_df = dataset_df[dataset_df['essay_set'] == 1].copy()\n",
        "essay_df.shape\n",
        "\n",
        "# essay_df = dataset_df.loc[(dataset_df['essay_set'] == 3) | (dataset_df['essay_set'] == 4) | (dataset_df['essay_set'] == 5) | (dataset_df['essay_set'] == 6)].copy()\n",
        "# essay_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide the 'score' column by 2 and round it\n",
        "essay_df['score'] = np.round(essay_df['score'] / 2)\n",
        "essay_df['score'].value_counts().sort_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPj-g9Jw6duf",
        "outputId": "281f53f7-2b7f-407a-9cb9-c5231c93b1d6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0      10\n",
              "2.0      35\n",
              "3.0     110\n",
              "4.0    1156\n",
              "5.0     316\n",
              "6.0     156\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the 'score' column to integers only\n",
        "essay_df['score'] = essay_df['score'].astype(int)\n",
        "essay_df['score'].value_counts().sort_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SECmlENh6oRc",
        "outputId": "629c7fff-4900-4ba0-c7e3-ebe8e4929e14"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1      10\n",
              "2      35\n",
              "3     110\n",
              "4    1156\n",
              "5     316\n",
              "6     156\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "sYnqfTkQxBzr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Use minimum score\n",
        "rater_1 = essay_df[\"rater1\"].to_numpy()\n",
        "rater_2 = essay_df[\"rater2\"].to_numpy()\n",
        "\n",
        "min_score = np.minimum(rater_1, rater_2)\n",
        "max_score = np.maximum(rater_1, rater_2)\n",
        "\n",
        "essay_df['min_score'] = min_score\n",
        "essay_df['max_score'] = max_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5iw8IEz3CTL",
        "outputId": "d52160a7-09b8-4672-ffdb-0eb2b4a848f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    1156\n",
              "5     316\n",
              "6     156\n",
              "3     110\n",
              "2      35\n",
              "1      10\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "essay_df['score'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df[target_column] - essay_df[target_column].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tSwyjSIMDEr",
        "outputId": "95ca8585-6a8c-4afe-f75e-635f8bab4964"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       3\n",
              "1       3\n",
              "2       3\n",
              "3       4\n",
              "4       3\n",
              "       ..\n",
              "1778    3\n",
              "1779    3\n",
              "1780    3\n",
              "1781    0\n",
              "1782    3\n",
              "Name: score, Length: 1783, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "w5oZj0cani-Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "essay_df['target_score'] = essay_df[target_column] - essay_df[target_column].min()\n",
        "\n",
        "X, y = essay_df['essay'].to_list(), essay_df['target_score'].to_numpy()\n",
        "num_labels = essay_df[target_column].unique().size\n",
        "\n",
        "# 60 / 40 train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) # stratify=y, this paramter will not work if any class has number of examples lower than 2\n",
        "\n",
        "# split test to half to get 60 / 20 / 20 split\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50, random_state=42) # stratify=y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "eng-OPm1Oavu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# a torch dataset implementation for ASAP dataset\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, essays, targets, tokenizer):\n",
        "        self.essays = essays\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.essays)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.essays[idx])\n",
        "        encoded_input = tokenizer(text, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "        return encoded_input['input_ids'].squeeze(), encoded_input['attention_mask'].squeeze(), self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "IkMVRTCKOWly"
      },
      "outputs": [],
      "source": [
        "# collater function to pad tokens\n",
        "def collate_fn(batch):\n",
        "    PAD_TOKEN_ID = 50256 # Use tokenizer.pad_token_id to check\n",
        "    input_ids_list, attention_mask_list, targets = [], [], []\n",
        "\n",
        "    for input_ids, attention_mask, target in batch:\n",
        "        input_ids_list.append(input_ids)\n",
        "        attention_mask_list.append(attention_mask)\n",
        "        targets.append(target)\n",
        "\n",
        "    # Pad the batch to the maximum sequence length within that batch using the tokenizer's pad token\n",
        "    max_length = max(len(ids) for ids in input_ids_list)\n",
        "    padded_input_ids = []\n",
        "    padded_attention_mask = []\n",
        "\n",
        "    for input_ids, attention_mask in zip(input_ids_list, attention_mask_list):\n",
        "        pad_length = max_length - len(input_ids)\n",
        "        padded_input_ids.append(torch.cat([input_ids, torch.tensor([PAD_TOKEN_ID] * pad_length, device=device, dtype=torch.long)]))\n",
        "        # add zeros to attention mask for padds\n",
        "        padded_attention_mask.append(torch.cat([attention_mask, torch.zeros(pad_length, dtype=torch.long, device=device)]))\n",
        "\n",
        "    return torch.stack(padded_input_ids), torch.stack(padded_attention_mask), torch.tensor(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "0AFe3puzOg9r"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(hp['base_model'])\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "RTB-6eCBHbB3"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "class ClassifierLayer(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size, bias=False):\n",
        "    super(ClassifierLayer, self).__init__()\n",
        "\n",
        "    self.dropout = torch.nn.Dropout(0.5)\n",
        "    self.linear = torch.nn.Linear(input_size, output_size, bias=bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inputs = self.dropout(x)\n",
        "    return self.linear(inputs)\n",
        "\n",
        "class GPT2Classification(GPT2ForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.score = ClassifierLayer(config.n_embd, self.num_labels, bias=False)\n",
        "\n",
        "        self.post_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLqTQ2PRqX12",
        "outputId": "d98c2925-bd56-401d-fd9d-271566069a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2Classification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "# use fp16 mixed precision to improve training speed\n",
        "accelerator = Accelerator(mixed_precision=hp['mixed_precision']) # fp16\n",
        "device = accelerator.device\n",
        "\n",
        "model = GPT2Classification.from_pretrained(hp['base_model'], num_labels=num_labels)\n",
        "#model = GPT2ForSequenceClassification.from_pretrained(hp['base_model'], num_labels=num_labels)\n",
        "model.to(device)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# fix model padding token id\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "DMkCwJR5vyKJ"
      },
      "outputs": [],
      "source": [
        "# train loop\n",
        "\n",
        "def train_loop(model, train_loader, val_loader, loss_fct, optimizer, lr_scheduler, progress_bar, log_file_handler, logging_step=1, use_amp=False):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "\n",
        "    for step, (inputs, attention_masks, targets) in enumerate(train_loader):\n",
        "        targets = targets.reshape(-1, 1).to(device)\n",
        "        attention_masks = attention_masks.to(device)\n",
        "        outputs = model(inputs, attention_mask=attention_masks)\n",
        "        loss = loss_fct(outputs[\"logits\"].view(-1, model.num_labels), targets.view(-1))\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        samples += inputs.shape[0]\n",
        "        cumulative_loss += loss.item()\n",
        "\n",
        "        if step % logging_step == 0:\n",
        "            # calculate qwk on test set\n",
        "\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_preds, qwk = test_loop(model, val_loader, loss_fct, use_amp=use_amp)\n",
        "            model.train()\n",
        "            log_str = \"Step: {:<6} \\t Train loss: {:<6.4f} \\t Validation loss: {:<6.4f} \\t QWK: {:<6.4f}\".format(step, (cumulative_loss/samples), test_loss, qwk)\n",
        "            print(log_str)\n",
        "            log_file_handler.write(log_str + \"\\n\")\n",
        "            samples = 0\n",
        "            cumulative_loss = 0\n",
        "\n",
        "    return cumulative_loss/samples if samples != 0 else float(\"inf\")\n",
        "\n",
        "def test_loop(model, test_loader, loss_fct, use_amp=False, show_progression=False):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    # set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    loop_iterator = enumerate(tqdm(test_loader)) if show_progression else enumerate(test_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (inputs, attention_masks, targets) in loop_iterator:\n",
        "            targets = targets.reshape(-1, 1).to(device)\n",
        "            inputs = inputs.to(device)\n",
        "            attention_masks = attention_masks.to(device)\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                outputs = model(inputs, attention_mask=attention_masks)\n",
        "            loss = loss_fct(outputs[\"logits\"].view(-1, model.num_labels), targets.view(-1))\n",
        "\n",
        "            samples += inputs.shape[0]\n",
        "            cumulative_loss += loss.item()\n",
        "\n",
        "            probs = outputs['logits'].softmax(-1) # probs\n",
        "            predictions = probs.argmax(-1) # predicted classes\n",
        "\n",
        "            labels.extend(targets.tolist())\n",
        "            preds.extend(predictions.tolist())\n",
        "\n",
        "        qwk = kappa(preds, labels)\n",
        "\n",
        "    return cumulative_loss/samples if samples != 0 else float(\"inf\"), np.asarray(preds, dtype=np.float32), qwk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "5B9TGk2Qq0p_"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto  import tqdm\n",
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "lr = hp['lr']\n",
        "num_epochs = hp['num_epochs']\n",
        "batch_size = hp['batch_size']\n",
        "use_amp = hp['use_amp']\n",
        "\n",
        "# create train data loader\n",
        "train_dataset = EssayDataset(X_train, y_train, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "# create test data loader\n",
        "test_dataset = EssayDataset(X_test, y_test, tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# create val data loader\n",
        "val_dataset = EssayDataset(X_val, y_val, tokenizer)\n",
        "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# # get class weights\n",
        "# class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "loss_fct = torch.nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer,\n",
        "    num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "# use accelerator prepare\n",
        "\n",
        "# removed val_loader from prepare command\n",
        "model, optimizer, train_loader, test_loader, val_loader, lr_scheduler = accelerator.prepare(\n",
        "    model, optimizer, train_loader, test_loader, val_loader, lr_scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "OWAD3PIW98zc"
      },
      "outputs": [],
      "source": [
        "def open_log_file(log_folder, essay_df, model, label_column: str, hyper_parameters):\n",
        "    # using time as a file name for logging\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    file_name = timestr + '.log'\n",
        "\n",
        "    # check if folder exists, create if it isn't\n",
        "    pathlib.Path(log_folder).mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # open file to log results\n",
        "    log_file = os.path.join(log_folder, file_name)\n",
        "    fp = open(log_file, \"a\")\n",
        "\n",
        "    fp.write(\"Log time: \" + timestr + \"\\n\")\n",
        "    fp.write(\"Essay classes: \" + str(essay_df['essay_set'].unique()) + \"\\n\")\n",
        "    fp.write(\"Using score column: \" + label_column + \"\\n\")\n",
        "    fp.write(\"Score distribution: \" + \"\\n\" + essay_df[label_column].value_counts().to_string() + \"\\n\")\n",
        "\n",
        "    fp.write(\"\\n--- Model parameters:\\n\")\n",
        "    fp.write(str(model))\n",
        "    fp.write('\\n')\n",
        "\n",
        "    fp.write(\"\\n--- Hyper parameters:\\n\")\n",
        "    for k, v in hyper_parameters.items():\n",
        "        fp.write(f\" {k:<25}: {v}\\n\")\n",
        "\n",
        "    fp.write('\\n')\n",
        "    fp.flush()\n",
        "    return fp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "hadgjIQ4ATKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260d429b-c978-436c-fdbf-fe0af018e62b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 16 00:26:47 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0              39W / 300W |  11094MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hekFmfqJAENE",
        "outputId": "82cd453b-68ca-4b09-8864-73f89e88096e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "sti5Zj9TJJnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ef569022fa94445cb663282c9818ac1c",
            "089129700f2c49468b7fe6a58325c9fd",
            "7d3f5f9c7ae9414da0512e661cc2549e",
            "c0ce3531f41f4628adc3709e6f06cb86",
            "5de77114fc224e18b73e5ef8291d7c8d",
            "875ac187c5484c679c4e4aa92e30fc7a",
            "80f8bd985f3e40afa7de4f7e60bf4ab5",
            "6bcd32157673439689f577320cbdef34",
            "c0d7dca40ff44ec0924586e3185b28c3",
            "52c62423b2e64ddca590df4c99ffb81a",
            "4ccd34ba90c34948a7e8c860bf0f696a"
          ]
        },
        "outputId": "93600628-e469-4791-a194-970a227aa3fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/14260 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef569022fa94445cb663282c9818ac1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0      \t Train loss: 2.4656 \t Validation loss: 4.5381 \t QWK: 0.0000\n",
            "Step: 237    \t Train loss: 1.9422 \t Validation loss: 0.8342 \t QWK: 0.0450\n",
            "Step: 474    \t Train loss: 0.6805 \t Validation loss: 0.6094 \t QWK: 0.0251\n",
            "Step: 711    \t Train loss: 0.5958 \t Validation loss: 0.5450 \t QWK: 0.0122\n",
            "Epoch: 1     \t Test  loss: 0.5437 \t QWK: 0.0122\n",
            "Step: 0      \t Train loss: 1.0670 \t Validation loss: 0.5428 \t QWK: 0.0122\n",
            "Step: 237    \t Train loss: 0.5710 \t Validation loss: 0.5152 \t QWK: 0.0191\n",
            "Step: 474    \t Train loss: 0.5435 \t Validation loss: 0.5056 \t QWK: 0.0000\n",
            "Step: 711    \t Train loss: 0.5575 \t Validation loss: 0.4832 \t QWK: 0.0000\n",
            "Epoch: 2     \t Test  loss: 0.4806 \t QWK: 0.0000\n",
            "Step: 0      \t Train loss: 0.2146 \t Validation loss: 0.4787 \t QWK: 0.0000\n",
            "Step: 237    \t Train loss: 0.5081 \t Validation loss: 0.4566 \t QWK: 0.0000\n",
            "Step: 474    \t Train loss: 0.5088 \t Validation loss: 0.4309 \t QWK: 0.0000\n",
            "Step: 711    \t Train loss: 0.5050 \t Validation loss: 0.4079 \t QWK: 0.0246\n",
            "Epoch: 3     \t Test  loss: 0.4079 \t QWK: 0.0246\n",
            "Step: 0      \t Train loss: 0.1399 \t Validation loss: 0.4078 \t QWK: 0.0246\n",
            "Step: 237    \t Train loss: 0.4400 \t Validation loss: 0.3859 \t QWK: 0.0000\n",
            "Step: 474    \t Train loss: 0.4618 \t Validation loss: 0.3695 \t QWK: 0.2151\n",
            "Step: 711    \t Train loss: 0.4560 \t Validation loss: 0.3466 \t QWK: 0.2831\n",
            "Epoch: 4     \t Test  loss: 0.3464 \t QWK: 0.2831\n",
            "Step: 0      \t Train loss: 0.1575 \t Validation loss: 0.3463 \t QWK: 0.2831\n",
            "Step: 237    \t Train loss: 0.3759 \t Validation loss: 0.3417 \t QWK: 0.4111\n",
            "Step: 474    \t Train loss: 0.4067 \t Validation loss: 0.3237 \t QWK: 0.3742\n",
            "Step: 711    \t Train loss: 0.4194 \t Validation loss: 0.3199 \t QWK: 0.4431\n",
            "Epoch: 5     \t Test  loss: 0.3200 \t QWK: 0.4431\n",
            "Step: 0      \t Train loss: 0.4353 \t Validation loss: 0.3202 \t QWK: 0.4431\n",
            "Step: 237    \t Train loss: 0.3726 \t Validation loss: 0.3171 \t QWK: 0.3994\n",
            "Step: 474    \t Train loss: 0.3845 \t Validation loss: 0.3129 \t QWK: 0.4561\n",
            "Step: 711    \t Train loss: 0.3836 \t Validation loss: 0.3229 \t QWK: 0.4308\n",
            "Epoch: 6     \t Test  loss: 0.3229 \t QWK: 0.4223\n",
            "Step: 0      \t Train loss: 0.3636 \t Validation loss: 0.3230 \t QWK: 0.4223\n",
            "Step: 237    \t Train loss: 0.3550 \t Validation loss: 0.3280 \t QWK: 0.4978\n",
            "Step: 474    \t Train loss: 0.3566 \t Validation loss: 0.3237 \t QWK: 0.4757\n",
            "Step: 711    \t Train loss: 0.3972 \t Validation loss: 0.3080 \t QWK: 0.4376\n",
            "Epoch: 7     \t Test  loss: 0.3080 \t QWK: 0.4376\n",
            "Step: 0      \t Train loss: 0.3962 \t Validation loss: 0.3079 \t QWK: 0.4376\n",
            "Step: 237    \t Train loss: 0.3954 \t Validation loss: 0.3075 \t QWK: 0.4725\n",
            "Step: 474    \t Train loss: 0.3353 \t Validation loss: 0.3009 \t QWK: 0.4686\n",
            "Step: 711    \t Train loss: 0.3434 \t Validation loss: 0.3002 \t QWK: 0.4796\n",
            "Epoch: 8     \t Test  loss: 0.3000 \t QWK: 0.4796\n",
            "Step: 0      \t Train loss: 1.2377 \t Validation loss: 0.3000 \t QWK: 0.4839\n",
            "Step: 237    \t Train loss: 0.3291 \t Validation loss: 0.3023 \t QWK: 0.4670\n",
            "Step: 474    \t Train loss: 0.3193 \t Validation loss: 0.2947 \t QWK: 0.4668\n",
            "Step: 711    \t Train loss: 0.3304 \t Validation loss: 0.2954 \t QWK: 0.5240\n",
            "Epoch: 9     \t Test  loss: 0.2947 \t QWK: 0.5240\n",
            "Step: 0      \t Train loss: 0.0897 \t Validation loss: 0.2942 \t QWK: 0.5214\n",
            "Step: 237    \t Train loss: 0.3415 \t Validation loss: 0.2910 \t QWK: 0.4898\n",
            "Step: 474    \t Train loss: 0.3175 \t Validation loss: 0.2943 \t QWK: 0.4807\n",
            "Step: 711    \t Train loss: 0.2918 \t Validation loss: 0.3050 \t QWK: 0.4995\n",
            "Epoch: 10    \t Test  loss: 0.3044 \t QWK: 0.4995\n",
            "Step: 0      \t Train loss: 0.0602 \t Validation loss: 0.3041 \t QWK: 0.4995\n",
            "Step: 237    \t Train loss: 0.2979 \t Validation loss: 0.2927 \t QWK: 0.5020\n",
            "Step: 474    \t Train loss: 0.2882 \t Validation loss: 0.3010 \t QWK: 0.4839\n",
            "Step: 711    \t Train loss: 0.3117 \t Validation loss: 0.2962 \t QWK: 0.5213\n",
            "Epoch: 11    \t Test  loss: 0.2970 \t QWK: 0.5213\n",
            "Step: 0      \t Train loss: 0.0635 \t Validation loss: 0.2978 \t QWK: 0.5050\n",
            "Step: 237    \t Train loss: 0.2787 \t Validation loss: 0.2921 \t QWK: 0.4967\n",
            "Step: 474    \t Train loss: 0.2864 \t Validation loss: 0.2959 \t QWK: 0.5170\n",
            "Step: 711    \t Train loss: 0.2643 \t Validation loss: 0.3086 \t QWK: 0.4953\n",
            "Epoch: 12    \t Test  loss: 0.3089 \t QWK: 0.4953\n",
            "Step: 0      \t Train loss: 0.6946 \t Validation loss: 0.3094 \t QWK: 0.4953\n",
            "Step: 237    \t Train loss: 0.2503 \t Validation loss: 0.2970 \t QWK: 0.5358\n",
            "Step: 474    \t Train loss: 0.2412 \t Validation loss: 0.3044 \t QWK: 0.5442\n",
            "Step: 711    \t Train loss: 0.2626 \t Validation loss: 0.2978 \t QWK: 0.5159\n",
            "Epoch: 13    \t Test  loss: 0.2977 \t QWK: 0.5438\n",
            "Step: 0      \t Train loss: 0.3639 \t Validation loss: 0.2977 \t QWK: 0.5438\n",
            "Step: 237    \t Train loss: 0.2548 \t Validation loss: 0.2947 \t QWK: 0.5263\n",
            "Step: 474    \t Train loss: 0.2318 \t Validation loss: 0.3074 \t QWK: 0.5050\n",
            "Step: 711    \t Train loss: 0.2239 \t Validation loss: 0.2988 \t QWK: 0.5108\n",
            "Epoch: 14    \t Test  loss: 0.2989 \t QWK: 0.5108\n",
            "Step: 0      \t Train loss: 0.1006 \t Validation loss: 0.2990 \t QWK: 0.5108\n",
            "Step: 237    \t Train loss: 0.2279 \t Validation loss: 0.3098 \t QWK: 0.4821\n",
            "Step: 474    \t Train loss: 0.2407 \t Validation loss: 0.3128 \t QWK: 0.5300\n",
            "Step: 711    \t Train loss: 0.2229 \t Validation loss: 0.3069 \t QWK: 0.4987\n",
            "Epoch: 15    \t Test  loss: 0.3073 \t QWK: 0.4987\n",
            "Step: 0      \t Train loss: 0.1401 \t Validation loss: 0.3074 \t QWK: 0.4987\n",
            "Step: 237    \t Train loss: 0.2084 \t Validation loss: 0.3411 \t QWK: 0.5016\n",
            "Step: 474    \t Train loss: 0.2146 \t Validation loss: 0.3306 \t QWK: 0.4921\n",
            "Step: 711    \t Train loss: 0.2082 \t Validation loss: 0.3359 \t QWK: 0.4658\n",
            "Epoch: 16    \t Test  loss: 0.3361 \t QWK: 0.4822\n",
            "Step: 0      \t Train loss: 0.1419 \t Validation loss: 0.3360 \t QWK: 0.4671\n",
            "Step: 237    \t Train loss: 0.1877 \t Validation loss: 0.3137 \t QWK: 0.5241\n",
            "Step: 474    \t Train loss: 0.2221 \t Validation loss: 0.3122 \t QWK: 0.5077\n",
            "Step: 711    \t Train loss: 0.1840 \t Validation loss: 0.3518 \t QWK: 0.4509\n",
            "Epoch: 17    \t Test  loss: 0.3516 \t QWK: 0.4509\n",
            "Step: 0      \t Train loss: 0.4724 \t Validation loss: 0.3509 \t QWK: 0.4509\n",
            "Step: 237    \t Train loss: 0.2035 \t Validation loss: 0.3595 \t QWK: 0.4731\n",
            "Step: 474    \t Train loss: 0.1951 \t Validation loss: 0.3206 \t QWK: 0.5241\n",
            "Step: 711    \t Train loss: 0.1690 \t Validation loss: 0.3343 \t QWK: 0.5176\n",
            "Epoch: 18    \t Test  loss: 0.3341 \t QWK: 0.5176\n",
            "Step: 0      \t Train loss: 0.1299 \t Validation loss: 0.3338 \t QWK: 0.5176\n",
            "Step: 237    \t Train loss: 0.1915 \t Validation loss: 0.3251 \t QWK: 0.5070\n",
            "Step: 474    \t Train loss: 0.1783 \t Validation loss: 0.3252 \t QWK: 0.5031\n",
            "Step: 711    \t Train loss: 0.1947 \t Validation loss: 0.3274 \t QWK: 0.5281\n",
            "Epoch: 19    \t Test  loss: 0.3277 \t QWK: 0.5281\n",
            "Step: 0      \t Train loss: 0.0552 \t Validation loss: 0.3279 \t QWK: 0.5281\n",
            "Step: 237    \t Train loss: 0.2075 \t Validation loss: 0.3295 \t QWK: 0.5281\n",
            "Step: 474    \t Train loss: 0.1711 \t Validation loss: 0.3338 \t QWK: 0.5281\n",
            "Step: 711    \t Train loss: 0.1786 \t Validation loss: 0.3325 \t QWK: 0.5140\n",
            "Epoch: 20    \t Test  loss: 0.3325 \t QWK: 0.5140\n",
            "Log file closed.\n"
          ]
        }
      ],
      "source": [
        "# Start logging to a file\n",
        "fp = open_log_file(log_folder, essay_df, model, label_column=target_column, hyper_parameters=hp)\n",
        "\n",
        "try:\n",
        "    # Start training\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    with accelerator.autocast():\n",
        "        fp.write(\"Training logs: \\n\\n\")\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = train_loop(model, train_loader, val_loader, loss_fct, optimizer, lr_scheduler, progress_bar, fp, logging_step=len(train_loader)//3, use_amp=hp['use_amp'])\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_preds, qwk = test_loop(model, test_loader, loss_fct)\n",
        "                log_string = \"Epoch: {:<6}\\t Test  loss: {:<6.4f} \\t QWK: {:<6.4f}\".format(epoch+1, test_loss, qwk)\n",
        "                print(log_string)\n",
        "                fp.write(log_string + \"\\n\")\n",
        "finally:\n",
        "    print(\"Log file closed.\")\n",
        "    fp.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef569022fa94445cb663282c9818ac1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_089129700f2c49468b7fe6a58325c9fd",
              "IPY_MODEL_7d3f5f9c7ae9414da0512e661cc2549e",
              "IPY_MODEL_c0ce3531f41f4628adc3709e6f06cb86"
            ],
            "layout": "IPY_MODEL_5de77114fc224e18b73e5ef8291d7c8d"
          }
        },
        "089129700f2c49468b7fe6a58325c9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875ac187c5484c679c4e4aa92e30fc7a",
            "placeholder": "​",
            "style": "IPY_MODEL_80f8bd985f3e40afa7de4f7e60bf4ab5",
            "value": "100%"
          }
        },
        "7d3f5f9c7ae9414da0512e661cc2549e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bcd32157673439689f577320cbdef34",
            "max": 14260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0d7dca40ff44ec0924586e3185b28c3",
            "value": 14260
          }
        },
        "c0ce3531f41f4628adc3709e6f06cb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c62423b2e64ddca590df4c99ffb81a",
            "placeholder": "​",
            "style": "IPY_MODEL_4ccd34ba90c34948a7e8c860bf0f696a",
            "value": " 14260/14260 [22:37&lt;00:00, 13.02it/s]"
          }
        },
        "5de77114fc224e18b73e5ef8291d7c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875ac187c5484c679c4e4aa92e30fc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f8bd985f3e40afa7de4f7e60bf4ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bcd32157673439689f577320cbdef34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d7dca40ff44ec0924586e3185b28c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52c62423b2e64ddca590df4c99ffb81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ccd34ba90c34948a7e8c860bf0f696a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}