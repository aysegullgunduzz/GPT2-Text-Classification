{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhHukHgpFgxi"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "# TODO: check lr scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ALCt2-aGrI0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import cohen_kappa_score as kappa\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import time\n",
        "import pathlib\n",
        "\n",
        "# log folder to save log files\n",
        "log_folder = '/content/drive/MyDrive/asap/'\n",
        "\n",
        "# target column\n",
        "target_column = \"score\"\n",
        "\n",
        "# hyper parameters\n",
        "hp = {\n",
        "    \"base_model\": \"gpt2\",\n",
        "    \"lr\": 1e-4,\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\":1,\n",
        "    \"use_amp\": True,\n",
        "    \"mixed_precision\": \"fp16\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5E6LL6CGlGU"
      },
      "source": [
        "# Prepare ASAP Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W-UI3sfsWEZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI4gDr87GohH"
      },
      "outputs": [],
      "source": [
        "# Original kaggle training set\n",
        "kaggle_dataset  = pd.read_csv('/content/drive/MyDrive/asap-aes/training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
        "\n",
        "# Smaller training set used for this project\n",
        "dataset_df = pd.DataFrame(\n",
        "  {\n",
        "    'essay_id' : kaggle_dataset['essay_id'],\n",
        "    'essay_set' : kaggle_dataset['essay_set'],\n",
        "    'essay' : kaggle_dataset['essay'],\n",
        "    'rater1' : kaggle_dataset['rater1_domain1'],\n",
        "    'rater2' : kaggle_dataset['rater2_domain1'],\n",
        "    'score' : kaggle_dataset['domain1_score']\n",
        "  })\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTmNpJqfHY2R"
      },
      "source": [
        "## Use essay_set=7 for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il-xAB2lHVvq"
      },
      "outputs": [],
      "source": [
        "essay_df = dataset_df[dataset_df['essay_set'] == 7].copy()\n",
        "essay_df.shape\n",
        "\n",
        "# essay_df = dataset_df.loc[(dataset_df['essay_set'] == 3) | (dataset_df['essay_set'] == 4) | (dataset_df['essay_set'] == 5) | (dataset_df['essay_set'] == 6)].copy()\n",
        "# essay_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Standardize the data\n",
        "scaler = StandardScaler()\n",
        "standart_veriler = scaler.fit_transform(essay_df[['score']])\n",
        "\n",
        "#Divide the standardized values into 4 classes: 0, 1, 2, 3\n",
        "#For example, divide into less than -3, between -2 and -1, between -1 and 0, and greater than 0\n",
        "\n",
        "bins = [-float(\"inf\"), -1, 0, 1, float(\"inf\")]\n",
        "labels = [0, 1, 2, 3]\n",
        "\n",
        "essay_df['score'] = pd.cut(standart_veriler.flatten(), bins=bins, labels=labels).astype(int)\n",
        "\n",
        "#Check the class counts\n",
        "sinif_sayilari = essay_df['score'].value_counts().sort_index()\n",
        "print(sinif_sayilari)"
      ],
      "metadata": {
        "id": "sFLZ8buy2Wkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYnqfTkQxBzr"
      },
      "outputs": [],
      "source": [
        "'''import numpy as np\n",
        "# Use minimum score\n",
        "rater_1 = essay_df[\"rater1\"].to_numpy()\n",
        "rater_2 = essay_df[\"rater2\"].to_numpy()\n",
        "\n",
        "min_score = np.minimum(rater_1, rater_2)\n",
        "max_score = np.maximum(rater_1, rater_2)\n",
        "\n",
        "essay_df['min_score'] = min_score\n",
        "essay_df['max_score'] = max_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5iw8IEz3CTL"
      },
      "outputs": [],
      "source": [
        "essay_df['score'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6'dan düşük skorları 6'ya yükseltme\n",
        "essay_df['score'] = essay_df['score'].apply(lambda x: 7 if x < 7 else x)\n",
        "# Yeni frekansları hesaplama\n",
        "new_frequencies = essay_df['score'].value_counts().sort_index()\n",
        "\n",
        "# Sonuçları gösterme\n",
        "print(new_frequencies)"
      ],
      "metadata": {
        "id": "X3dCyFrsnH7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df['score'] = essay_df['score'].astype(int)\n"
      ],
      "metadata": {
        "id": "SWbndlqL0pkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Standardize the data\n",
        "scaler = StandardScaler()\n",
        "essay_df[['score']] = scaler.fit_transform(essay_df[['score']])\n"
      ],
      "metadata": {
        "id": "ksmQN9hKF0b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5oZj0cani-Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "essay_df['target_score'] = essay_df[target_column] - essay_df[target_column].min()\n",
        "\n",
        "X, y = essay_df['essay'].to_list(), essay_df['target_score'].to_numpy()\n",
        "num_labels = essay_df[target_column].unique().size\n",
        "\n",
        "# 60 / 40 train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42) # stratify=y, this paramter will not work if any class has number of examples lower than 2\n",
        "\n",
        "# split test to half to get 60 / 20 / 20 split\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50, random_state=42) # stratify=y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eng-OPm1Oavu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, essays, targets, tokenizer, device):\n",
        "        self.essays = essays\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.essays)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.essays[idx])\n",
        "        # Ensure that the tokenizer and device are used correctly\n",
        "        encoded_input = self.tokenizer(text, truncation=True, return_tensors='pt')\n",
        "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
        "\n",
        "        # It's better to ensure the target is a tensor and on the correct device\n",
        "        target = torch.tensor(self.targets[idx], dtype=torch.long).to(self.device)\n",
        "\n",
        "        return encoded_input['input_ids'].squeeze(), encoded_input['attention_mask'].squeeze(), target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkMVRTCKOWly"
      },
      "outputs": [],
      "source": [
        "# collater function to pad tokens\n",
        "def collate_fn(batch):\n",
        "    PAD_TOKEN_ID = 50256 # Use tokenizer.pad_token_id to check\n",
        "    input_ids_list, attention_mask_list, targets = [], [], []\n",
        "\n",
        "    for input_ids, attention_mask, target in batch:\n",
        "        input_ids_list.append(input_ids)\n",
        "        attention_mask_list.append(attention_mask)\n",
        "        targets.append(target)\n",
        "\n",
        "    # Pad the batch to the maximum sequence length within that batch using the tokenizer's pad token\n",
        "    max_length = max(len(ids) for ids in input_ids_list)\n",
        "    padded_input_ids = []\n",
        "    padded_attention_mask = []\n",
        "\n",
        "    for input_ids, attention_mask in zip(input_ids_list, attention_mask_list):\n",
        "        pad_length = max_length - len(input_ids)\n",
        "        padded_input_ids.append(torch.cat([input_ids, torch.tensor([PAD_TOKEN_ID] * pad_length, device=device, dtype=torch.long)]))\n",
        "        # add zeros to attention mask for padds\n",
        "        padded_attention_mask.append(torch.cat([attention_mask, torch.zeros(pad_length, dtype=torch.long, device=device)]))\n",
        "\n",
        "    return torch.stack(padded_input_ids), torch.stack(padded_attention_mask), torch.tensor(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AFe3puzOg9r"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(hp['base_model'])\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTB-6eCBHbB3"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "class ClassifierLayer(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size, bias=False):\n",
        "    super(ClassifierLayer, self).__init__()\n",
        "\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.linear = torch.nn.Linear(input_size, output_size, bias=bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inputs = self.dropout(x)\n",
        "    return self.linear(inputs)\n",
        "\n",
        "class GPT2Classification(GPT2ForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.score = ClassifierLayer(config.n_embd, self.num_labels, bias=False)\n",
        "\n",
        "        self.post_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLqTQ2PRqX12"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "# use fp16 mixed precision to improve training speed\n",
        "accelerator = Accelerator(mixed_precision=hp['mixed_precision']) # fp16\n",
        "device = accelerator.device\n",
        "\n",
        "model = GPT2Classification.from_pretrained(hp['base_model'], num_labels=num_labels)\n",
        "#model = GPT2ForSequenceClassification.from_pretrained(hp['base_model'], num_labels=num_labels)\n",
        "model.to(device)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# fix model padding token id\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMkCwJR5vyKJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# train loop\n",
        "\n",
        "def train_loop(model, train_loader, val_loader, loss_fct, optimizer, lr_scheduler, progress_bar, log_file_handler, logging_step=1, use_amp=False):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "\n",
        "    for step, (inputs, attention_masks, targets) in enumerate(train_loader):\n",
        "        targets = targets.reshape(-1, 1).to(device)\n",
        "        attention_masks = attention_masks.to(device)\n",
        "        outputs = model(inputs, attention_mask=attention_masks)\n",
        "        loss = loss_fct(outputs[\"logits\"].view(-1, model.num_labels), targets.view(-1))\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        samples += inputs.shape[0]\n",
        "        cumulative_loss += loss.item()\n",
        "\n",
        "        if step % logging_step == 0:\n",
        "            # calculate cls_report on test set\n",
        "\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_preds, cls_report = test_loop(model, val_loader, loss_fct, use_amp=use_amp)\n",
        "            model.train()\n",
        "            log_str = \"Step: {:<6} \\t Train loss: {:<6.4f} \\t Validation loss: {:<6.4f}\".format(step, (cumulative_loss/samples), test_loss)\n",
        "            # Adding f1 accuracy recall prec metics\n",
        "            log_str += \"\\n\" + cls_report\n",
        "            print(log_str)\n",
        "            log_file_handler.write(log_str + \"\\n\")\n",
        "            samples = 0\n",
        "            cumulative_loss = 0\n",
        "\n",
        "    return cumulative_loss/samples if samples != 0 else float(\"inf\")\n",
        "\n",
        "def test_loop(model, test_loader, loss_fct, use_amp=False, show_progression=False):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    # set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    loop_iterator = enumerate(tqdm(test_loader)) if show_progression else enumerate(test_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (inputs, attention_masks, targets) in loop_iterator:\n",
        "            targets = targets.reshape(-1, 1).to(device)\n",
        "            inputs = inputs.to(device)\n",
        "            attention_masks = attention_masks.to(device)\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                outputs = model(inputs, attention_mask=attention_masks)\n",
        "            loss = loss_fct(outputs[\"logits\"].view(-1, model.num_labels), targets.view(-1))\n",
        "\n",
        "            samples += inputs.shape[0]\n",
        "            cumulative_loss += loss.item()\n",
        "\n",
        "            probs = outputs['logits'].softmax(-1) # probs\n",
        "            predictions = probs.argmax(-1) # predicted classes\n",
        "\n",
        "            labels.extend(targets.tolist())\n",
        "            preds.extend(predictions.tolist())\n",
        "\n",
        "        cls_report = classification_report(labels, preds, zero_division=0)\n",
        "\n",
        "    return cumulative_loss/samples if samples != 0 else float(\"inf\"), np.asarray(preds, dtype=np.float32), cls_report\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B9TGk2Qq0p_"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto  import tqdm\n",
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "lr = hp['lr']\n",
        "num_epochs = hp['num_epochs']\n",
        "batch_size = hp['batch_size']\n",
        "use_amp = hp['use_amp']\n",
        "\n",
        "# Assuming that 'accelerator' is already imported and initialized\n",
        "device = accelerator.device  # Using the device associated with the accelerator\n",
        "\n",
        "# Assuming that X_train, y_train, tokenizer are already defined and properly set up\n",
        "# Create training dataset and DataLoader\n",
        "train_dataset = EssayDataset(X_train, y_train, tokenizer, device)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "# create test data loader\n",
        "test_dataset = EssayDataset(X_test, y_test, tokenizer, device)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# create val data loader\n",
        "val_dataset = EssayDataset(X_val, y_val, tokenizer, device)\n",
        "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# # get class weights\n",
        "# class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "loss_fct = torch.nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer,\n",
        "    num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "# use accelerator prepare\n",
        "\n",
        "# removed val_loader from prepare command\n",
        "model, optimizer, train_loader, test_loader, val_loader, lr_scheduler = accelerator.prepare(\n",
        "    model, optimizer, train_loader, test_loader, val_loader, lr_scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWAD3PIW98zc"
      },
      "outputs": [],
      "source": [
        "def open_log_file(log_folder, essay_df, model, label_column: str, hyper_parameters):\n",
        "    # using time as a file name for logging\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    file_name = timestr + '.log'\n",
        "\n",
        "    # check if folder exists, create if it isn't\n",
        "    pathlib.Path(log_folder).mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # open file to log results\n",
        "    log_file = os.path.join(log_folder, file_name)\n",
        "    fp = open(log_file, \"a\")\n",
        "\n",
        "    fp.write(\"Log time: \" + timestr + \"\\n\")\n",
        "    fp.write(\"Essay classes: \" + str(essay_df['essay_set'].unique()) + \"\\n\")\n",
        "    fp.write(\"Using score column: \" + label_column + \"\\n\")\n",
        "    fp.write(\"Score distribution: \" + \"\\n\" + essay_df[label_column].value_counts().to_string() + \"\\n\")\n",
        "\n",
        "    fp.write(\"\\n--- Model parameters:\\n\")\n",
        "    fp.write(str(model))\n",
        "    fp.write('\\n')\n",
        "\n",
        "    fp.write(\"\\n--- Hyper parameters:\\n\")\n",
        "    for k, v in hyper_parameters.items():\n",
        "        fp.write(f\" {k:<25}: {v}\\n\")\n",
        "\n",
        "    fp.write('\\n')\n",
        "    fp.flush()\n",
        "    return fp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "hadgjIQ4ATKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "hekFmfqJAENE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sti5Zj9TJJnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9b8b9a836eee4d0e924833acef3cbff1",
            "017c7e8452c6455f8317c753795ca8e0",
            "6529a35cb06e449b9e397826bb551079",
            "9e2dd57594744ef38aee811d03f432b5",
            "ff0e3ef35a134345b2ad2e2bb85041b1",
            "ca01d90a7e564ce59bd5086176107e99",
            "3912b1720915473ca32fcb22a7b53a76",
            "3b108aab349d4ea2a9eae4c6dde7fb2f",
            "65669d0d0b3545fbaadb3cf696f84262",
            "0228a6400ece4c50a398324471a4f9ce",
            "fa8a393bd1074e508815d1637a55c90c"
          ]
        },
        "outputId": "8c6a236c-3d17-431b-bbcd-af575c33cb35"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b8b9a836eee4d0e924833acef3cbff1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28230 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0      \t Train loss: 0.4862 \t Validation loss: 1.2014\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.29      0.44        55\n",
            "           1       0.57      0.58      0.57       110\n",
            "           2       0.42      0.47      0.44        88\n",
            "           3       0.53      0.75      0.63        61\n",
            "\n",
            "    accuracy                           0.53       314\n",
            "   macro avg       0.62      0.52      0.52       314\n",
            "weighted avg       0.58      0.53      0.52       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.8699 \t Validation loss: 1.3889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.49      0.58        55\n",
            "           1       0.62      0.27      0.38       110\n",
            "           2       0.36      0.50      0.42        88\n",
            "           3       0.48      0.82      0.61        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.48       314\n",
            "   macro avg       0.43      0.42      0.40       314\n",
            "weighted avg       0.54      0.48      0.47       314\n",
            "\n",
            "Step: 626    \t Train loss: 0.7976 \t Validation loss: 1.1660\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.38      0.49        55\n",
            "           1       0.54      0.41      0.47       110\n",
            "           2       0.39      0.58      0.47        88\n",
            "           3       0.52      0.59      0.55        61\n",
            "\n",
            "    accuracy                           0.49       314\n",
            "   macro avg       0.53      0.49      0.49       314\n",
            "weighted avg       0.52      0.49      0.49       314\n",
            "\n",
            "Step: 939    \t Train loss: 0.8210 \t Validation loss: 1.1902\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.38      0.51        55\n",
            "           1       0.57      0.41      0.48       110\n",
            "           2       0.42      0.70      0.53        88\n",
            "           3       0.57      0.57      0.57        61\n",
            "\n",
            "    accuracy                           0.52       314\n",
            "   macro avg       0.59      0.52      0.52       314\n",
            "weighted avg       0.57      0.52      0.52       314\n",
            "\n",
            "Epoch: 1     \t Test  loss: 1.1860\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.38      0.51        55\n",
            "           1       0.57      0.42      0.48       110\n",
            "           2       0.42      0.70      0.53        88\n",
            "           3       0.59      0.59      0.59        61\n",
            "\n",
            "    accuracy                           0.53       314\n",
            "   macro avg       0.59      0.52      0.53       314\n",
            "weighted avg       0.57      0.53      0.52       314\n",
            "\n",
            "Step: 0      \t Train loss: 0.1588 \t Validation loss: 1.1817\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.38      0.51        55\n",
            "           1       0.58      0.43      0.49       110\n",
            "           2       0.43      0.70      0.53        88\n",
            "           3       0.59      0.59      0.59        61\n",
            "\n",
            "    accuracy                           0.53       314\n",
            "   macro avg       0.59      0.53      0.53       314\n",
            "weighted avg       0.57      0.53      0.53       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.6924 \t Validation loss: 1.3903\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.44      0.55        55\n",
            "           1       0.62      0.26      0.37       110\n",
            "           2       0.38      0.64      0.48        88\n",
            "           3       0.55      0.79      0.65        61\n",
            "\n",
            "    accuracy                           0.50       314\n",
            "   macro avg       0.57      0.53      0.51       314\n",
            "weighted avg       0.56      0.50      0.48       314\n",
            "\n",
            "Step: 626    \t Train loss: 0.6112 \t Validation loss: 1.5537\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.51      0.57        55\n",
            "           1       0.58      0.29      0.39       110\n",
            "           2       0.34      0.31      0.32        88\n",
            "           3       0.40      0.90      0.56        61\n",
            "\n",
            "    accuracy                           0.45       314\n",
            "   macro avg       0.49      0.50      0.46       314\n",
            "weighted avg       0.49      0.45      0.43       314\n",
            "\n",
            "Step: 939    \t Train loss: 0.6597 \t Validation loss: 1.5511\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.55      0.64        55\n",
            "           1       0.68      0.23      0.34       110\n",
            "           2       0.37      0.60      0.46        88\n",
            "           3       0.50      0.77      0.61        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.49       314\n",
            "   macro avg       0.46      0.43      0.41       314\n",
            "weighted avg       0.57      0.49      0.48       314\n",
            "\n",
            "Epoch: 2     \t Test  loss: 1.5640\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.55      0.64        55\n",
            "           1       0.68      0.23      0.34       110\n",
            "           2       0.37      0.60      0.46        88\n",
            "           3       0.50      0.77      0.61        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.49       314\n",
            "   macro avg       0.46      0.43      0.41       314\n",
            "weighted avg       0.57      0.49      0.48       314\n",
            "\n",
            "Step: 0      \t Train loss: 0.6183 \t Validation loss: 1.5840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.55      0.64        55\n",
            "           1       0.66      0.21      0.32       110\n",
            "           2       0.37      0.60      0.46        88\n",
            "           3       0.50      0.77      0.61        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.49       314\n",
            "   macro avg       0.46      0.43      0.40       314\n",
            "weighted avg       0.57      0.49      0.47       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.5122 \t Validation loss: 1.5190\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.69      0.63        55\n",
            "           1       0.62      0.21      0.31       110\n",
            "           2       0.39      0.38      0.38        88\n",
            "           3       0.42      0.87      0.56        61\n",
            "\n",
            "    accuracy                           0.47       314\n",
            "   macro avg       0.50      0.54      0.47       314\n",
            "weighted avg       0.51      0.47      0.44       314\n",
            "\n",
            "Step: 626    \t Train loss: 0.5500 \t Validation loss: 1.2959\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.60      0.61        55\n",
            "           1       0.64      0.37      0.47       110\n",
            "           2       0.42      0.61      0.50        88\n",
            "           3       0.57      0.64      0.60        61\n",
            "\n",
            "    accuracy                           0.53       314\n",
            "   macro avg       0.56      0.56      0.55       314\n",
            "weighted avg       0.56      0.53      0.53       314\n",
            "\n",
            "Step: 939    \t Train loss: 0.5100 \t Validation loss: 1.2397\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.44      0.54        55\n",
            "           1       0.61      0.57      0.59       110\n",
            "           2       0.48      0.55      0.51        88\n",
            "           3       0.57      0.70      0.63        61\n",
            "\n",
            "    accuracy                           0.57       314\n",
            "   macro avg       0.59      0.56      0.57       314\n",
            "weighted avg       0.58      0.57      0.57       314\n",
            "\n",
            "Epoch: 3     \t Test  loss: 1.2369\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.44      0.53        55\n",
            "           1       0.61      0.58      0.60       110\n",
            "           2       0.49      0.55      0.52        88\n",
            "           3       0.57      0.70      0.63        61\n",
            "\n",
            "    accuracy                           0.57       314\n",
            "   macro avg       0.59      0.57      0.57       314\n",
            "weighted avg       0.58      0.57      0.57       314\n",
            "\n",
            "Step: 0      \t Train loss: 0.0729 \t Validation loss: 1.2353\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.44      0.53        55\n",
            "           1       0.61      0.58      0.60       110\n",
            "           2       0.49      0.55      0.52        88\n",
            "           3       0.57      0.70      0.63        61\n",
            "\n",
            "    accuracy                           0.57       314\n",
            "   macro avg       0.59      0.57      0.57       314\n",
            "weighted avg       0.58      0.57      0.57       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.4077 \t Validation loss: 1.3132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.49      0.53        55\n",
            "           1       0.61      0.44      0.51       110\n",
            "           2       0.45      0.59      0.51        88\n",
            "           3       0.58      0.69      0.63        61\n",
            "\n",
            "    accuracy                           0.54       314\n",
            "   macro avg       0.55      0.55      0.54       314\n",
            "weighted avg       0.55      0.54      0.54       314\n",
            "\n",
            "Step: 626    \t Train loss: 0.3785 \t Validation loss: 1.5951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.40      0.51        55\n",
            "           1       0.58      0.28      0.38       110\n",
            "           2       0.40      0.61      0.48        88\n",
            "           3       0.49      0.77      0.60        61\n",
            "\n",
            "    accuracy                           0.49       314\n",
            "   macro avg       0.55      0.52      0.49       314\n",
            "weighted avg       0.54      0.49      0.48       314\n",
            "\n",
            "Step: 939    \t Train loss: 0.4186 \t Validation loss: 1.5217\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.76      0.65        55\n",
            "           1       0.69      0.23      0.34       110\n",
            "           2       0.43      0.57      0.49        88\n",
            "           3       0.50      0.72      0.59        61\n",
            "\n",
            "    accuracy                           0.51       314\n",
            "   macro avg       0.55      0.57      0.52       314\n",
            "weighted avg       0.56      0.51      0.49       314\n",
            "\n",
            "Epoch: 4     \t Test  loss: 1.5013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.75      0.64        55\n",
            "           1       0.68      0.24      0.35       110\n",
            "           2       0.44      0.58      0.50        88\n",
            "           3       0.51      0.72      0.59        61\n",
            "\n",
            "    accuracy                           0.52       314\n",
            "   macro avg       0.55      0.57      0.52       314\n",
            "weighted avg       0.56      0.52      0.49       314\n",
            "\n",
            "Step: 0      \t Train loss: 0.2272 \t Validation loss: 1.4781\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.75      0.64        55\n",
            "           1       0.69      0.25      0.36       110\n",
            "           2       0.44      0.58      0.50        88\n",
            "           3       0.51      0.72      0.59        61\n",
            "\n",
            "    accuracy                           0.52       314\n",
            "   macro avg       0.55      0.57      0.53       314\n",
            "weighted avg       0.56      0.52      0.50       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.3212 \t Validation loss: 1.7426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.76      0.65        55\n",
            "           1       0.76      0.17      0.28       110\n",
            "           2       0.43      0.56      0.49        88\n",
            "           3       0.50      0.84      0.63        61\n",
            "\n",
            "    accuracy                           0.51       314\n",
            "   macro avg       0.57      0.58      0.51       314\n",
            "weighted avg       0.58      0.51      0.47       314\n",
            "\n",
            "Step: 626    \t Train loss: 0.2576 \t Validation loss: 1.3208\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.60      0.62        55\n",
            "           1       0.63      0.58      0.60       110\n",
            "           2       0.49      0.51      0.50        88\n",
            "           3       0.57      0.64      0.60        61\n",
            "\n",
            "    accuracy                           0.58       314\n",
            "   macro avg       0.58      0.58      0.58       314\n",
            "weighted avg       0.58      0.58      0.58       314\n",
            "\n",
            "Step: 939    \t Train loss: 0.2580 \t Validation loss: 1.5255\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.69      0.64        55\n",
            "           1       0.67      0.34      0.45       110\n",
            "           2       0.44      0.64      0.52        88\n",
            "           3       0.59      0.67      0.63        61\n",
            "\n",
            "    accuracy                           0.55       314\n",
            "   macro avg       0.58      0.58      0.56       314\n",
            "weighted avg       0.58      0.55      0.54       314\n",
            "\n",
            "Epoch: 5     \t Test  loss: 1.5205\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.69      0.64        55\n",
            "           1       0.66      0.34      0.45       110\n",
            "           2       0.44      0.62      0.52        88\n",
            "           3       0.59      0.67      0.63        61\n",
            "\n",
            "    accuracy                           0.54       314\n",
            "   macro avg       0.57      0.58      0.56       314\n",
            "weighted avg       0.57      0.54      0.54       314\n",
            "\n",
            "Step: 0      \t Train loss: 0.1132 \t Validation loss: 1.5187\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.69      0.64        55\n",
            "           1       0.66      0.34      0.45       110\n",
            "           2       0.44      0.62      0.52        88\n",
            "           3       0.59      0.67      0.63        61\n",
            "\n",
            "    accuracy                           0.54       314\n",
            "   macro avg       0.57      0.58      0.56       314\n",
            "weighted avg       0.57      0.54      0.54       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.2562 \t Validation loss: 1.8653\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.55      0.58        55\n",
            "           1       0.72      0.28      0.41       110\n",
            "           2       0.41      0.53      0.46        88\n",
            "           3       0.49      0.84      0.61        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.51       314\n",
            "   macro avg       0.44      0.44      0.41       314\n",
            "weighted avg       0.57      0.51      0.49       314\n",
            "\n",
            "Step: 626    \t Train loss: 0.2058 \t Validation loss: 1.5359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.69      0.62        55\n",
            "           1       0.64      0.38      0.48       110\n",
            "           2       0.48      0.58      0.52        88\n",
            "           3       0.59      0.72      0.65        61\n",
            "\n",
            "    accuracy                           0.56       314\n",
            "   macro avg       0.57      0.59      0.57       314\n",
            "weighted avg       0.57      0.56      0.55       314\n",
            "\n",
            "Step: 939    \t Train loss: 0.1865 \t Validation loss: 2.0237\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.62      0.65        55\n",
            "           1       0.75      0.22      0.34       110\n",
            "           2       0.38      0.59      0.46        88\n",
            "           3       0.51      0.79      0.62        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50       314\n",
            "   macro avg       0.46      0.44      0.41       314\n",
            "weighted avg       0.59      0.50      0.48       314\n",
            "\n",
            "Epoch: 6     \t Test  loss: 2.0518\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.60      0.63        55\n",
            "           1       0.73      0.20      0.31       110\n",
            "           2       0.38      0.59      0.46        88\n",
            "           3       0.52      0.82      0.64        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50       314\n",
            "   macro avg       0.46      0.44      0.41       314\n",
            "weighted avg       0.58      0.50      0.47       314\n",
            "\n",
            "Step: 0      \t Train loss: 0.0354 \t Validation loss: 2.0748\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.60      0.63        55\n",
            "           1       0.75      0.19      0.30       110\n",
            "           2       0.37      0.59      0.46        88\n",
            "           3       0.53      0.84      0.65        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50       314\n",
            "   macro avg       0.46      0.44      0.41       314\n",
            "weighted avg       0.59      0.50      0.47       314\n",
            "\n",
            "Step: 313    \t Train loss: 0.1993 \t Validation loss: 1.8695\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.73      0.62        55\n",
            "           1       0.62      0.23      0.33       110\n",
            "           2       0.44      0.55      0.48        88\n",
            "           3       0.53      0.75      0.62        61\n",
            "          12       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.51       314\n",
            "   macro avg       0.42      0.45      0.41       314\n",
            "weighted avg       0.54      0.51      0.48       314\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Start logging to a file\n",
        "fp = open_log_file(log_folder, essay_df, model, label_column=target_column, hyper_parameters=hp)\n",
        "\n",
        "try:\n",
        "    # Start training\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    with accelerator.autocast():\n",
        "        fp.write(\"Training logs: \\n\\n\")\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = train_loop(model, train_loader, val_loader, loss_fct, optimizer, lr_scheduler, progress_bar, fp, logging_step=len(train_loader)//3, use_amp=hp['use_amp'])\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_preds, cls_report = test_loop(model, test_loader, loss_fct)\n",
        "                log_string = \"Epoch: {:<6}\\t Test  loss: {:<6.4f}\".format(epoch+1, test_loss)\n",
        "                log_string += \"\\n\" + cls_report\n",
        "                print(log_string)\n",
        "                fp.write(log_string + \"\\n\")\n",
        "finally:\n",
        "    print(\"Log file closed.\")\n",
        "    fp.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "V8VDB6BnLnlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oh_isSwIkf-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "display = ConfusionMatrixDisplay.from_predictions(y_test, test_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0iUYxxvKpZU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, test_preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b8b9a836eee4d0e924833acef3cbff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_017c7e8452c6455f8317c753795ca8e0",
              "IPY_MODEL_6529a35cb06e449b9e397826bb551079",
              "IPY_MODEL_9e2dd57594744ef38aee811d03f432b5"
            ],
            "layout": "IPY_MODEL_ff0e3ef35a134345b2ad2e2bb85041b1"
          }
        },
        "017c7e8452c6455f8317c753795ca8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca01d90a7e564ce59bd5086176107e99",
            "placeholder": "​",
            "style": "IPY_MODEL_3912b1720915473ca32fcb22a7b53a76",
            "value": " 21%"
          }
        },
        "6529a35cb06e449b9e397826bb551079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b108aab349d4ea2a9eae4c6dde7fb2f",
            "max": 28230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65669d0d0b3545fbaadb3cf696f84262",
            "value": 6053
          }
        },
        "9e2dd57594744ef38aee811d03f432b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0228a6400ece4c50a398324471a4f9ce",
            "placeholder": "​",
            "style": "IPY_MODEL_fa8a393bd1074e508815d1637a55c90c",
            "value": " 6053/28230 [11:47&lt;33:17, 11.10it/s]"
          }
        },
        "ff0e3ef35a134345b2ad2e2bb85041b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca01d90a7e564ce59bd5086176107e99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3912b1720915473ca32fcb22a7b53a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b108aab349d4ea2a9eae4c6dde7fb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65669d0d0b3545fbaadb3cf696f84262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0228a6400ece4c50a398324471a4f9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8a393bd1074e508815d1637a55c90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}