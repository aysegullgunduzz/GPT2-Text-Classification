{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhHukHgpFgxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066f8dd4-fa98-4072-ef8e-d5534e391bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "# TODO: check lr scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ALCt2-aGrI0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import cohen_kappa_score as kappa\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import time\n",
        "import pathlib\n",
        "\n",
        "# log folder to save log files\n",
        "log_folder = '/content/drive/MyDrive/asap/'\n",
        "\n",
        "# target column\n",
        "target_column = \"score\"\n",
        "\n",
        "# hyper parameters\n",
        "hp = {\n",
        "    \"base_model\": \"gpt2\",\n",
        "    \"lr\": 1e-4,\n",
        "    \"num_epochs\": 30,\n",
        "    \"batch_size\":2,\n",
        "    \"use_amp\": True,\n",
        "    \"mixed_precision\": \"fp16\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5E6LL6CGlGU"
      },
      "source": [
        "# Prepare ASAP Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-UI3sfsWEZi",
        "outputId": "35c00263-f6e0-451b-d990-b37a952b718f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI4gDr87GohH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2f6e63c0-be23-4231-c192-95a1bbe22f5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   rater1  rater2  rater3  score  \n",
              "0       4       4     NaN      8  \n",
              "1       5       4     NaN      9  \n",
              "2       4       3     NaN      7  \n",
              "3       5       5     NaN     10  \n",
              "4       4       4     NaN      8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-785ca7bc-dd6b-4aee-a8f3-f03417a0b9f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1</th>\n",
              "      <th>rater2</th>\n",
              "      <th>rater3</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-785ca7bc-dd6b-4aee-a8f3-f03417a0b9f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-785ca7bc-dd6b-4aee-a8f3-f03417a0b9f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-785ca7bc-dd6b-4aee-a8f3-f03417a0b9f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36ada1e1-20f6-42fe-a1ce-9a286d246e29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36ada1e1-20f6-42fe-a1ce-9a286d246e29')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36ada1e1-20f6-42fe-a1ce-9a286d246e29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Original kaggle training set\n",
        "kaggle_dataset  = pd.read_csv('/content/drive/MyDrive/GPT-2 MODEL/training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
        "\n",
        "# Smaller training set used for this project\n",
        "dataset_df = pd.DataFrame(\n",
        "  {\n",
        "    'essay_id' : kaggle_dataset['essay_id'],\n",
        "    'essay_set' : kaggle_dataset['essay_set'],\n",
        "    'essay' : kaggle_dataset['essay'],\n",
        "    'rater1' : kaggle_dataset['rater1_domain1'],\n",
        "    'rater2' : kaggle_dataset['rater2_domain1'],\n",
        "    'rater3' : kaggle_dataset['rater3_domain1'],\n",
        "    'score' : kaggle_dataset['domain1_score']\n",
        "  })\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTmNpJqfHY2R"
      },
      "source": [
        "## Use essay_set=8 for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il-xAB2lHVvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cfedeb-210d-4c32-e95d-babe21cab64d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(723, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "essay_df = dataset_df[dataset_df['essay_set'] == 8].copy()\n",
        "essay_df.shape\n",
        "\n",
        "# essay_df = dataset_df.loc[(dataset_df['essay_set'] == 3) | (dataset_df['essay_set'] == 4) | (dataset_df['essay_set'] == 5) | (dataset_df['essay_set'] == 6)].copy()\n",
        "# essay_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(essay_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCikWbUuDzrV",
        "outputId": "48728d44-d527-4d51-fd93-2ab72fae116d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       essay_id  essay_set                                              essay  \\\n",
            "12253     20716          8   A long time ago when I was in third grade I h...   \n",
            "12254     20717          8   Softball has to be one of the single most gre...   \n",
            "12255     20718          8   Some people like making people laugh, I love ...   \n",
            "12256     20719          8   \"LAUGHTER\"  @CAPS1 I hang out with my friends...   \n",
            "12257     20721          8  Well ima tell a story about the time i got @CA...   \n",
            "...         ...        ...                                                ...   \n",
            "12971     21626          8   In most stories mothers and daughters are eit...   \n",
            "12972     21628          8   I never understood the meaning laughter is th...   \n",
            "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
            "12974     21630          8                                 Trippin' on fen...   \n",
            "12975     21633          8   Many people believe that laughter can improve...   \n",
            "\n",
            "       rater1  rater2  rater3  score  \n",
            "12253      18      16     NaN     34  \n",
            "12254      21      26    46.0     46  \n",
            "12255      15      20    40.0     40  \n",
            "12256      12      20    30.0     30  \n",
            "12257      11      15     NaN     26  \n",
            "...       ...     ...     ...    ...  \n",
            "12971      17      18     NaN     35  \n",
            "12972      15      17     NaN     32  \n",
            "12973      20      26    40.0     40  \n",
            "12974      20      20     NaN     40  \n",
            "12975      20      20     NaN     40  \n",
            "\n",
            "[723 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the value of each group\n",
        "essay_df['score'].value_counts().sort_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h87BtWsDvNgq",
        "outputId": "12da6fee-3f4a-45b2-c53d-53cad700c1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10      1\n",
              "15      1\n",
              "20      4\n",
              "21      2\n",
              "22      1\n",
              "24      3\n",
              "25      5\n",
              "26      4\n",
              "27      6\n",
              "28     11\n",
              "29      8\n",
              "30     49\n",
              "31     34\n",
              "32     37\n",
              "33     32\n",
              "34     39\n",
              "35     47\n",
              "36     65\n",
              "37     39\n",
              "38     20\n",
              "39      8\n",
              "40    161\n",
              "41     22\n",
              "42     23\n",
              "43     15\n",
              "44     14\n",
              "45     31\n",
              "46     13\n",
              "47      7\n",
              "48      3\n",
              "49      2\n",
              "50     13\n",
              "55      2\n",
              "60      1\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the 'score' column to integers only\n",
        "essay_df['score'] = essay_df['score'].astype(int)\n"
      ],
      "metadata": {
        "id": "eQlNbueF_gGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the classes to new values in order\n",
        "unique_scores = sorted(essay_df['score'].unique())\n",
        "mapping = {score: i+1 for i, score in enumerate(unique_scores)}\n",
        "\n",
        "#Update the dataset.\n",
        "essay_df['score'] = essay_df['score'].map(mapping)\n",
        "\n",
        "#Check the recount\n",
        "print(essay_df['score'].value_counts().sort_index())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjoQLtnu_5jw",
        "outputId": "06d5e144-6859-44c8-e81a-23895f3585c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1       1\n",
            "2       1\n",
            "3       4\n",
            "4       2\n",
            "5       1\n",
            "6       3\n",
            "7       5\n",
            "8       4\n",
            "9       6\n",
            "10     11\n",
            "11      8\n",
            "12     49\n",
            "13     34\n",
            "14     37\n",
            "15     32\n",
            "16     39\n",
            "17     47\n",
            "18     65\n",
            "19     39\n",
            "20     20\n",
            "21      8\n",
            "22    161\n",
            "23     22\n",
            "24     23\n",
            "25     15\n",
            "26     14\n",
            "27     31\n",
            "28     13\n",
            "29      7\n",
            "30      3\n",
            "31      2\n",
            "32     13\n",
            "33      2\n",
            "34      1\n",
            "Name: score, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df['score'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2kLYZgzn9_T",
        "outputId": "306d3f78-9597-46ea-9b7a-21fc6670cd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22    161\n",
              "18     65\n",
              "12     49\n",
              "17     47\n",
              "16     39\n",
              "19     39\n",
              "14     37\n",
              "13     34\n",
              "15     32\n",
              "27     31\n",
              "24     23\n",
              "23     22\n",
              "20     20\n",
              "25     15\n",
              "26     14\n",
              "28     13\n",
              "32     13\n",
              "10     11\n",
              "21      8\n",
              "11      8\n",
              "29      7\n",
              "9       6\n",
              "7       5\n",
              "8       4\n",
              "3       4\n",
              "6       3\n",
              "30      3\n",
              "31      2\n",
              "33      2\n",
              "4       2\n",
              "34      1\n",
              "2       1\n",
              "5       1\n",
              "1       1\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_LXGn52uzQc",
        "outputId": "a5b3c50b-8a9f-4954-dd38-7aefc81646b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google_trans_new\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fugYYiTM9tsh",
        "outputId": "f754ba4b-5de6-4090-ad6d-feb9db351d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google_trans_new in /usr/local/lib/python3.10/dist-packages (1.1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import pandas as pd\n",
        "\n",
        "def back_translate(text):\n",
        "    translator = Translator()\n",
        "    target_language = 'tr'\n",
        "\n",
        "    try:\n",
        "        translated_text = translator.translate(text, dest=target_language).text\n",
        "        back_translated_text = translator.translate(translated_text, dest='en').text\n",
        "        return back_translated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Çeviri hatası: {e}\")\n",
        "        return text  # Hata durumunda orijinal metni kullanın\n",
        "\n",
        "\n",
        "def augment_data(df, column, value, fraction):\n",
        "    subset = df[df[column] == value]\n",
        "    augmented_subset = subset.sample(frac=fraction, replace=True)\n",
        "\n",
        "    new_rows = []\n",
        "    max_essay_id = df['essay_id'].max()\n",
        "\n",
        "    for _, row in augmented_subset.iterrows():\n",
        "        max_essay_id += 1\n",
        "        new_rows.append({\n",
        "            'essay_id': max_essay_id,\n",
        "            'essay_set': row['essay_set'],\n",
        "            'essay': back_translate(row['essay']),\n",
        "            'rater1': row['rater1'],\n",
        "            'rater2': row['rater2'],\n",
        "            'score': value\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(new_rows)\n",
        "\n",
        "# essay_df üzerine veri artırma uygulama\n",
        "classes_to_augment = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
        "augmented_dataframes = []\n",
        "\n",
        "for value in classes_to_augment:\n",
        "    augmented_dataframes.append(augment_data(essay_df, 'score', value, 1))\n",
        "\n",
        "augmented_df = pd.concat(augmented_dataframes, ignore_index=True)\n",
        "\n",
        "#Artırılmış veriyi orijinal veriye ekleyin\n",
        "essay_df = pd.concat([essay_df, augmented_df], ignore_index=True)\n",
        "\n",
        "print(f\"Total data size after augmentation: {len(essay_df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hK1iexSuzes",
        "outputId": "84efe076-696d-46b7-c5cd-d7332782d708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Çeviri hatası: the JSON object must be str, bytes or bytearray, not NoneType\n",
            "Total data size after augmentation: 1220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df['score'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dY3rLf9HvSL",
        "outputId": "22cc5acc-105b-487e-a115-7a9cce1526e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22    161\n",
              "12     98\n",
              "17     94\n",
              "16     78\n",
              "19     78\n",
              "14     74\n",
              "13     68\n",
              "18     65\n",
              "15     64\n",
              "27     62\n",
              "24     46\n",
              "23     44\n",
              "20     40\n",
              "25     30\n",
              "26     28\n",
              "28     26\n",
              "32     26\n",
              "10     22\n",
              "21     16\n",
              "11     16\n",
              "29     14\n",
              "9      12\n",
              "7      10\n",
              "8       8\n",
              "3       8\n",
              "6       6\n",
              "30      6\n",
              "31      4\n",
              "33      4\n",
              "4       4\n",
              "34      2\n",
              "2       2\n",
              "5       2\n",
              "1       2\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6'dan düşük skorları 6'ya yükseltme\n",
        "essay_df['score2'] = essay_df['score'].apply(lambda x: 29 if x < 29 else x)\n",
        "# Yeni frekansları hesaplama\n",
        "new_frequencies = essay_df['score2'].value_counts().sort_index()\n",
        "\n",
        "# 6'dan düşük skorları 6'ya yükseltme\n",
        "essay_df['score2'] = essay_df['score2'].apply(lambda x: 38 if x == 39 else x)\n",
        "# Yeni frekansları hesaplama\n",
        "# Assuming 'score1' is the column with the scores\n",
        "# Replace score 55 with 50, and any score less than 6 with 60\n",
        "\n",
        "essay_df['score2'] = essay_df['score2'].apply(lambda x: 50 if x == 60 else x)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'essay_df' is your DataFrame and 'score1' is the column of interest\n",
        "\n",
        "# Filter the DataFrame to exclude rows where 'score1' is 47, 48, or 60\n",
        "filtered_df = essay_df[~essay_df['score2'].isin([47, 48, 49, 55, 60])]\n",
        "\n",
        "# If you want to update 'essay_df' directly and use it further, just overwrite it:\n",
        "essay_df = filtered_df.copy()\n",
        "\n",
        "# Calculate the new frequencies after the removal\n",
        "new_frequencies = essay_df['score2'].value_counts().sort_index()\n",
        "\n",
        "# Print the new frequencies\n",
        "print(new_frequencies)\n",
        "essay_df['score'] = essay_df['score2']"
      ],
      "metadata": {
        "id": "3S2iDggEnE9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df['score'].value_counts().sort_index()\n"
      ],
      "metadata": {
        "id": "AMgEiArud1F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7133468d-0080-4dc7-97af-3f032a10ad8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     24\n",
              "2    166\n",
              "3    443\n",
              "4    385\n",
              "5    166\n",
              "6     36\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(essay_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9npM1ahaENHE",
        "outputId": "89045269-4922-4b95-8a2d-842259437e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      essay_id  essay_set                                              essay  \\\n",
            "0        20716          8   A long time ago when I was in third grade I h...   \n",
            "1        20717          8   Softball has to be one of the single most gre...   \n",
            "2        20718          8   Some people like making people laugh, I love ...   \n",
            "3        20719          8   \"LAUGHTER\"  @CAPS1 I hang out with my friends...   \n",
            "4        20721          8  Well ima tell a story about the time i got @CA...   \n",
            "...        ...        ...                                                ...   \n",
            "1215     21645          8  \" @Caps1 day diamonds and @caps1 day stone,\" @...   \n",
            "1216     21646          8  The laughter creates a bond between the two pe...   \n",
            "1217     21634          8  @Caps1-inspirational, @caps2 @caps4 i @caps5 @...   \n",
            "1218     21635          8  @Caps1-inspirational, @caps2 @caps4 i @caps5 @...   \n",
            "1219     21634          8  Bell rings.! Chocolate Hair and Mocha bound, i...   \n",
            "\n",
            "      rater1  rater2  rater3  score  \n",
            "0         18      16     NaN      3  \n",
            "1         21      26    46.0      5  \n",
            "2         15      20    40.0      4  \n",
            "3         12      20    30.0      2  \n",
            "4         11      15     NaN      2  \n",
            "...      ...     ...     ...    ...  \n",
            "1215      25      25     NaN      6  \n",
            "1216      27      20     NaN      6  \n",
            "1217      30      25     NaN      6  \n",
            "1218      30      25     NaN      6  \n",
            "1219      30      30     NaN      6  \n",
            "\n",
            "[1220 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYnqfTkQxBzr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Use minimum score\n",
        "rater_1 = essay_df[\"rater1\"].to_numpy()\n",
        "rater_2 = essay_df[\"rater2\"].to_numpy()\n",
        "\n",
        "min_score = np.minimum(rater_1, rater_2)\n",
        "max_score = np.maximum(rater_1, rater_2)\n",
        "\n",
        "essay_df['min_score'] = min_score\n",
        "essay_df['max_score'] = max_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5iw8IEz3CTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0602b0b-c303-4d50-898c-a73357af8843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    443\n",
              "4    385\n",
              "5    166\n",
              "2    166\n",
              "6     36\n",
              "1     24\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "essay_df['score'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df[target_column] - essay_df[target_column].min()"
      ],
      "metadata": {
        "id": "5tSwyjSIMDEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fc9eb1-9936-4287-b555-7841ba1a232e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2\n",
              "1       4\n",
              "2       3\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "1215    5\n",
              "1216    5\n",
              "1217    5\n",
              "1218    5\n",
              "1219    5\n",
              "Name: score, Length: 1220, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(essay_df[target_column])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f78oK5AEPGPF",
        "outputId": "8a691235-ee0d-47cc-a049-d28de81b0974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       3\n",
            "1       5\n",
            "2       4\n",
            "3       2\n",
            "4       2\n",
            "       ..\n",
            "1215    6\n",
            "1216    6\n",
            "1217    6\n",
            "1218    6\n",
            "1219    6\n",
            "Name: score, Length: 1220, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5oZj0cani-Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "essay_df['target_score'] = essay_df[target_column] - essay_df[target_column].min()\n",
        "\n",
        "X, y = essay_df['essay'].to_list(), essay_df['target_score'].to_numpy()\n",
        "num_labels = essay_df[target_column].unique().size\n",
        "\n",
        "# 60 / 40 train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42) # stratify=y, this paramter will not work if any class has number of examples lower than 2\n",
        "\n",
        "# split test to half to get 60 / 20 / 20 split\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.50, random_state=42) # stratify=y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eng-OPm1Oavu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# a torch dataset implementation for ASAP dataset\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, essays, targets, tokenizer):\n",
        "        self.essays = essays\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.essays)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.essays[idx])\n",
        "        encoded_input = tokenizer(text, truncation=True, return_tensors='pt').to(device)\n",
        "\n",
        "        return encoded_input['input_ids'].squeeze(), encoded_input['attention_mask'].squeeze(), self.targets[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkMVRTCKOWly"
      },
      "outputs": [],
      "source": [
        "# collater function to pad tokens\n",
        "def collate_fn(batch):\n",
        "    PAD_TOKEN_ID = 50256 # Use tokenizer.pad_token_id to check\n",
        "    input_ids_list, attention_mask_list, targets = [], [], []\n",
        "\n",
        "    for input_ids, attention_mask, target in batch:\n",
        "        input_ids_list.append(input_ids)\n",
        "        attention_mask_list.append(attention_mask)\n",
        "        targets.append(target)\n",
        "\n",
        "    # Pad the batch to the maximum sequence length within that batch using the tokenizer's pad token\n",
        "    max_length = max(len(ids) for ids in input_ids_list)\n",
        "    padded_input_ids = []\n",
        "    padded_attention_mask = []\n",
        "\n",
        "    for input_ids, attention_mask in zip(input_ids_list, attention_mask_list):\n",
        "        pad_length = max_length - len(input_ids)\n",
        "        padded_input_ids.append(torch.cat([input_ids, torch.tensor([PAD_TOKEN_ID] * pad_length, device=device, dtype=torch.long)]))\n",
        "        # add zeros to attention mask for padds\n",
        "        padded_attention_mask.append(torch.cat([attention_mask, torch.zeros(pad_length, dtype=torch.long, device=device)]))\n",
        "\n",
        "    return torch.stack(padded_input_ids), torch.stack(padded_attention_mask), torch.tensor(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AFe3puzOg9r"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(hp['base_model'])\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTB-6eCBHbB3"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "class ClassifierLayer(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size, bias=False):\n",
        "    super(ClassifierLayer, self).__init__()\n",
        "\n",
        "    self.dropout = torch.nn.Dropout(0.1)\n",
        "    self.linear = torch.nn.Linear(input_size, output_size, bias=bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inputs = self.dropout(x)\n",
        "    return self.linear(inputs)\n",
        "\n",
        "class GPT2Classification(GPT2ForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.score = ClassifierLayer(config.n_embd, self.num_labels, bias=False)\n",
        "\n",
        "        self.post_init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLqTQ2PRqX12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3688ed5-063e-47a7-82fd-0131ed892cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2Classification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "# use fp16 mixed precision to improve training speed\n",
        "accelerator = Accelerator(mixed_precision=hp['mixed_precision']) # fp16\n",
        "device = accelerator.device\n",
        "\n",
        "model = GPT2Classification.from_pretrained(hp['base_model'], num_labels=num_labels)\n",
        "#model = GPT2ForSequenceClassification.from_pretrained(hp['base_model'], num_labels=num_labels)\n",
        "model.to(device)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "# fix model padding token id\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMkCwJR5vyKJ"
      },
      "outputs": [],
      "source": [
        "# train loop\n",
        "\n",
        "def train_loop(model, train_loader, val_loader, loss_fct, optimizer, lr_scheduler, progress_bar, log_file_handler, logging_step=1, use_amp=False):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "\n",
        "    for step, (inputs, attention_masks, targets) in enumerate(train_loader):\n",
        "        targets = targets.reshape(-1, 1).to(device)\n",
        "        attention_masks = attention_masks.to(device)\n",
        "        outputs = model(inputs, attention_mask=attention_masks)\n",
        "        loss = loss_fct(outputs[\"logits\"].view(-1, model.num_labels), targets.view(-1))\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "        samples += inputs.shape[0]\n",
        "        cumulative_loss += loss.item()\n",
        "\n",
        "        if step % logging_step == 0:\n",
        "            # calculate qwk on test set\n",
        "\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_preds, qwk = test_loop(model, val_loader, loss_fct, use_amp=use_amp)\n",
        "            model.train()\n",
        "            log_str = \"Step: {:<6} \\t Train loss: {:<6.4f} \\t Validation loss: {:<6.4f} \\t QWK: {:<6.4f}\".format(step, (cumulative_loss/samples), test_loss, qwk)\n",
        "            print(log_str)\n",
        "            log_file_handler.write(log_str + \"\\n\")\n",
        "            samples = 0\n",
        "            cumulative_loss = 0\n",
        "\n",
        "    return cumulative_loss/samples if samples != 0 else float(\"inf\")\n",
        "\n",
        "def test_loop(model, test_loader, loss_fct, use_amp=False, show_progression=False):\n",
        "    samples = 0.\n",
        "    cumulative_loss = 0.\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    # set model to eval mode\n",
        "    model.eval()\n",
        "\n",
        "    loop_iterator = enumerate(tqdm(test_loader)) if show_progression else enumerate(test_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (inputs, attention_masks, targets) in loop_iterator:\n",
        "            targets = targets.reshape(-1, 1).to(device)\n",
        "            inputs = inputs.to(device)\n",
        "            attention_masks = attention_masks.to(device)\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                outputs = model(inputs, attention_mask=attention_masks)\n",
        "            loss = loss_fct(outputs[\"logits\"].view(-1, model.num_labels), targets.view(-1))\n",
        "\n",
        "            samples += inputs.shape[0]\n",
        "            cumulative_loss += loss.item()\n",
        "\n",
        "            probs = outputs['logits'].softmax(-1) # probs\n",
        "            predictions = probs.argmax(-1) # predicted classes\n",
        "\n",
        "            labels.extend(targets.tolist())\n",
        "            preds.extend(predictions.tolist())\n",
        "\n",
        "        qwk = kappa(preds, labels, weights='quadratic')\n",
        "\n",
        "    return cumulative_loss/samples if samples != 0 else float(\"inf\"), np.asarray(preds, dtype=np.float32), qwk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B9TGk2Qq0p_"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto  import tqdm\n",
        "from transformers import get_scheduler\n",
        "from torch.optim import AdamW\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "lr = hp['lr']\n",
        "num_epochs = hp['num_epochs']\n",
        "batch_size = hp['batch_size']\n",
        "use_amp = hp['use_amp']\n",
        "\n",
        "# create train data loader\n",
        "train_dataset = EssayDataset(X_train, y_train, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "# create test data loader\n",
        "test_dataset = EssayDataset(X_test, y_test, tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# create val data loader\n",
        "val_dataset = EssayDataset(X_val, y_val, tokenizer)\n",
        "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# # get class weights\n",
        "# class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "# class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "loss_fct = torch.nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"polynomial\", optimizer=optimizer,\n",
        "    num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "# use accelerator prepare\n",
        "\n",
        "# removed val_loader from prepare command\n",
        "model, optimizer, train_loader, test_loader, val_loader, lr_scheduler = accelerator.prepare(\n",
        "    model, optimizer, train_loader, test_loader, val_loader, lr_scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWAD3PIW98zc"
      },
      "outputs": [],
      "source": [
        "def open_log_file(log_folder, essay_df, model, label_column: str, hyper_parameters):\n",
        "    # using time as a file name for logging\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    file_name = timestr + '.log'\n",
        "\n",
        "    # check if folder exists, create if it isn't\n",
        "    pathlib.Path(log_folder).mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # open file to log results\n",
        "    log_file = os.path.join(log_folder, file_name)\n",
        "    fp = open(log_file, \"a\")\n",
        "\n",
        "    fp.write(\"Log time: \" + timestr + \"\\n\")\n",
        "    fp.write(\"Essay classes: \" + str(essay_df['essay_set'].unique()) + \"\\n\")\n",
        "    fp.write(\"Using score column: \" + label_column + \"\\n\")\n",
        "    fp.write(\"Score distribution: \" + \"\\n\" + essay_df[label_column].value_counts().to_string() + \"\\n\")\n",
        "\n",
        "    fp.write(\"\\n--- Model parameters:\\n\")\n",
        "    fp.write(str(model))\n",
        "    fp.write('\\n')\n",
        "\n",
        "    fp.write(\"\\n--- Hyper parameters:\\n\")\n",
        "    for k, v in hyper_parameters.items():\n",
        "        fp.write(f\" {k:<25}: {v}\\n\")\n",
        "\n",
        "    fp.write('\\n')\n",
        "    fp.flush()\n",
        "    return fp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "hadgjIQ4ATKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84cb271-041e-425b-f46d-bec5f543d7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 10 21:22:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W /  70W |   1213MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "hekFmfqJAENE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf867d0-6837-4daa-8d5e-f515eb206b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sti5Zj9TJJnx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05d98d9a7bc344fab5e22218b13714b5",
            "bb46eba0c8f04dd08398f2cb19c49918",
            "8a50b975788140fd9074bb1ad1cedee4",
            "3085142b83644827a86888d924e30de7",
            "0f5bec4f8fc646c08ab4199309bea7ca",
            "68ff7d074c214e7da6ea794f74ea5c65",
            "394fd096a43749e5a0b3fe68558944fd",
            "9bc8b72ba4cb488a9bbd41941c02b190",
            "e0f3c70b6426400484c7ae49f00c8d41",
            "5c43e85af2654e29a905771294ab34f5",
            "6f50380f96584ebc95816de70b140f3d"
          ]
        },
        "outputId": "c4eed44d-dda1-43f0-f7e1-4c4d3a5538fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10980 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05d98d9a7bc344fab5e22218b13714b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0      \t Train loss: 4.4398 \t Validation loss: 5.1833 \t QWK: -0.0399\n",
            "Step: 122    \t Train loss: 2.6370 \t Validation loss: 1.4189 \t QWK: 0.0631\n",
            "Step: 244    \t Train loss: 1.1034 \t Validation loss: 1.0960 \t QWK: 0.0466\n",
            "Epoch: 1     \t Test  loss: 1.0455 \t QWK: 0.0485\n",
            "Step: 0      \t Train loss: 0.7189 \t Validation loss: 1.0446 \t QWK: 0.0485\n",
            "Step: 122    \t Train loss: 0.7990 \t Validation loss: 0.9565 \t QWK: 0.0841\n",
            "Step: 244    \t Train loss: 0.8252 \t Validation loss: 0.8633 \t QWK: 0.1370\n",
            "Epoch: 2     \t Test  loss: 0.8834 \t QWK: 0.0736\n",
            "Step: 0      \t Train loss: 0.4460 \t Validation loss: 0.8827 \t QWK: 0.0736\n",
            "Step: 122    \t Train loss: 0.7528 \t Validation loss: 0.8408 \t QWK: 0.1392\n",
            "Step: 244    \t Train loss: 0.7438 \t Validation loss: 0.8067 \t QWK: 0.1935\n",
            "Epoch: 3     \t Test  loss: 0.7822 \t QWK: 0.2421\n",
            "Step: 0      \t Train loss: 0.6124 \t Validation loss: 0.7797 \t QWK: 0.2459\n",
            "Step: 122    \t Train loss: 0.6934 \t Validation loss: 0.7754 \t QWK: 0.2122\n",
            "Step: 244    \t Train loss: 0.7066 \t Validation loss: 0.7788 \t QWK: 0.2035\n",
            "Epoch: 4     \t Test  loss: 0.8606 \t QWK: 0.1183\n",
            "Step: 0      \t Train loss: 0.6506 \t Validation loss: 0.8612 \t QWK: 0.1183\n",
            "Step: 122    \t Train loss: 0.6667 \t Validation loss: 0.7741 \t QWK: 0.2482\n",
            "Step: 244    \t Train loss: 0.6525 \t Validation loss: 0.7916 \t QWK: 0.2507\n",
            "Epoch: 5     \t Test  loss: 0.8257 \t QWK: 0.2043\n",
            "Step: 0      \t Train loss: 0.5020 \t Validation loss: 0.8250 \t QWK: 0.2087\n",
            "Step: 122    \t Train loss: 0.6294 \t Validation loss: 0.7980 \t QWK: 0.2342\n",
            "Step: 244    \t Train loss: 0.6567 \t Validation loss: 0.7725 \t QWK: 0.2327\n",
            "Epoch: 6     \t Test  loss: 0.7698 \t QWK: 0.2709\n",
            "Step: 0      \t Train loss: 0.7178 \t Validation loss: 0.7564 \t QWK: 0.2729\n",
            "Step: 122    \t Train loss: 0.5933 \t Validation loss: 0.8643 \t QWK: 0.2089\n",
            "Step: 244    \t Train loss: 0.5660 \t Validation loss: 0.9410 \t QWK: 0.1994\n",
            "Epoch: 7     \t Test  loss: 0.6828 \t QWK: 0.3963\n",
            "Step: 0      \t Train loss: 1.0043 \t Validation loss: 0.6829 \t QWK: 0.3839\n",
            "Step: 122    \t Train loss: 0.5061 \t Validation loss: 0.8686 \t QWK: 0.2499\n",
            "Step: 244    \t Train loss: 0.4910 \t Validation loss: 1.0604 \t QWK: 0.1727\n",
            "Epoch: 8     \t Test  loss: 0.7595 \t QWK: 0.2939\n",
            "Step: 0      \t Train loss: 0.2718 \t Validation loss: 0.7647 \t QWK: 0.2924\n",
            "Step: 122    \t Train loss: 0.4065 \t Validation loss: 0.8838 \t QWK: 0.2495\n",
            "Step: 244    \t Train loss: 0.3950 \t Validation loss: 0.7914 \t QWK: 0.2803\n",
            "Epoch: 9     \t Test  loss: 0.9611 \t QWK: 0.2460\n",
            "Step: 0      \t Train loss: 0.1688 \t Validation loss: 0.9666 \t QWK: 0.2444\n",
            "Step: 122    \t Train loss: 0.2973 \t Validation loss: 0.8937 \t QWK: 0.2715\n",
            "Step: 244    \t Train loss: 0.3164 \t Validation loss: 0.8462 \t QWK: 0.2811\n",
            "Epoch: 10    \t Test  loss: 0.8528 \t QWK: 0.3172\n",
            "Step: 0      \t Train loss: 0.3125 \t Validation loss: 0.8621 \t QWK: 0.3065\n",
            "Step: 122    \t Train loss: 0.2484 \t Validation loss: 0.8113 \t QWK: 0.3642\n",
            "Step: 244    \t Train loss: 0.2158 \t Validation loss: 0.9876 \t QWK: 0.2927\n",
            "Epoch: 11    \t Test  loss: 0.7858 \t QWK: 0.4470\n",
            "Step: 0      \t Train loss: 0.0552 \t Validation loss: 0.7826 \t QWK: 0.4432\n",
            "Step: 122    \t Train loss: 0.1863 \t Validation loss: 0.6814 \t QWK: 0.5149\n",
            "Step: 244    \t Train loss: 0.1780 \t Validation loss: 0.8553 \t QWK: 0.4200\n",
            "Epoch: 12    \t Test  loss: 1.0135 \t QWK: 0.3521\n",
            "Step: 0      \t Train loss: 0.0282 \t Validation loss: 1.0117 \t QWK: 0.3564\n",
            "Step: 122    \t Train loss: 0.1621 \t Validation loss: 0.8916 \t QWK: 0.4871\n",
            "Step: 244    \t Train loss: 0.1525 \t Validation loss: 0.8820 \t QWK: 0.4320\n",
            "Epoch: 13    \t Test  loss: 0.8889 \t QWK: 0.4309\n",
            "Step: 0      \t Train loss: 0.0190 \t Validation loss: 0.8923 \t QWK: 0.4225\n",
            "Step: 122    \t Train loss: 0.1062 \t Validation loss: 1.0392 \t QWK: 0.4174\n",
            "Step: 244    \t Train loss: 0.1180 \t Validation loss: 0.7743 \t QWK: 0.5022\n",
            "Epoch: 14    \t Test  loss: 0.8134 \t QWK: 0.5228\n",
            "Step: 0      \t Train loss: 0.0412 \t Validation loss: 0.8026 \t QWK: 0.5245\n",
            "Step: 122    \t Train loss: 0.0780 \t Validation loss: 0.8333 \t QWK: 0.4822\n",
            "Step: 244    \t Train loss: 0.1000 \t Validation loss: 0.8267 \t QWK: 0.5213\n",
            "Epoch: 15    \t Test  loss: 0.7767 \t QWK: 0.5541\n",
            "Step: 0      \t Train loss: 0.0267 \t Validation loss: 0.7809 \t QWK: 0.5537\n",
            "Step: 122    \t Train loss: 0.0666 \t Validation loss: 0.7957 \t QWK: 0.5704\n",
            "Step: 244    \t Train loss: 0.0858 \t Validation loss: 0.8415 \t QWK: 0.5492\n",
            "Epoch: 16    \t Test  loss: 0.8549 \t QWK: 0.5214\n",
            "Step: 0      \t Train loss: 0.0598 \t Validation loss: 0.8607 \t QWK: 0.5214\n",
            "Step: 122    \t Train loss: 0.0759 \t Validation loss: 0.6995 \t QWK: 0.5740\n",
            "Step: 244    \t Train loss: 0.0526 \t Validation loss: 0.8700 \t QWK: 0.5660\n",
            "Epoch: 17    \t Test  loss: 0.7008 \t QWK: 0.5906\n",
            "Step: 0      \t Train loss: 0.0702 \t Validation loss: 0.7076 \t QWK: 0.5897\n",
            "Step: 122    \t Train loss: 0.0653 \t Validation loss: 0.7093 \t QWK: 0.5676\n",
            "Step: 244    \t Train loss: 0.0658 \t Validation loss: 0.7726 \t QWK: 0.6095\n",
            "Epoch: 18    \t Test  loss: 0.7721 \t QWK: 0.5862\n",
            "Step: 0      \t Train loss: 0.1020 \t Validation loss: 0.7685 \t QWK: 0.5865\n",
            "Step: 122    \t Train loss: 0.0572 \t Validation loss: 0.7951 \t QWK: 0.5667\n",
            "Step: 244    \t Train loss: 0.0627 \t Validation loss: 0.8672 \t QWK: 0.5549\n",
            "Epoch: 19    \t Test  loss: 0.9389 \t QWK: 0.5775\n",
            "Step: 0      \t Train loss: 0.0141 \t Validation loss: 0.9458 \t QWK: 0.5775\n",
            "Step: 122    \t Train loss: 0.0372 \t Validation loss: 0.9139 \t QWK: 0.5375\n",
            "Step: 244    \t Train loss: 0.0578 \t Validation loss: 0.8806 \t QWK: 0.5712\n",
            "Epoch: 20    \t Test  loss: 0.7244 \t QWK: 0.6163\n",
            "Step: 0      \t Train loss: 0.0508 \t Validation loss: 0.7242 \t QWK: 0.6152\n",
            "Step: 122    \t Train loss: 0.0489 \t Validation loss: 0.7874 \t QWK: 0.6249\n",
            "Step: 244    \t Train loss: 0.0308 \t Validation loss: 0.8209 \t QWK: 0.5923\n",
            "Epoch: 21    \t Test  loss: 0.7527 \t QWK: 0.6357\n",
            "Step: 0      \t Train loss: 0.0330 \t Validation loss: 0.7540 \t QWK: 0.6357\n",
            "Step: 122    \t Train loss: 0.0502 \t Validation loss: 0.8042 \t QWK: 0.6033\n",
            "Step: 244    \t Train loss: 0.0402 \t Validation loss: 0.7973 \t QWK: 0.6145\n",
            "Epoch: 22    \t Test  loss: 0.7709 \t QWK: 0.6223\n",
            "Step: 0      \t Train loss: 0.0348 \t Validation loss: 0.7706 \t QWK: 0.6227\n",
            "Step: 122    \t Train loss: 0.0351 \t Validation loss: 0.8488 \t QWK: 0.5793\n",
            "Step: 244    \t Train loss: 0.0483 \t Validation loss: 0.8281 \t QWK: 0.5795\n",
            "Epoch: 23    \t Test  loss: 0.7663 \t QWK: 0.6036\n",
            "Step: 0      \t Train loss: 0.0010 \t Validation loss: 0.7651 \t QWK: 0.6036\n",
            "Step: 122    \t Train loss: 0.0368 \t Validation loss: 0.7659 \t QWK: 0.6117\n",
            "Step: 244    \t Train loss: 0.0429 \t Validation loss: 0.8678 \t QWK: 0.5899\n",
            "Epoch: 24    \t Test  loss: 0.7794 \t QWK: 0.6206\n",
            "Step: 0      \t Train loss: 0.0098 \t Validation loss: 0.7782 \t QWK: 0.6206\n",
            "Step: 122    \t Train loss: 0.0439 \t Validation loss: 0.8463 \t QWK: 0.5960\n",
            "Step: 244    \t Train loss: 0.0338 \t Validation loss: 0.9436 \t QWK: 0.5969\n",
            "Epoch: 25    \t Test  loss: 0.8024 \t QWK: 0.6371\n",
            "Step: 0      \t Train loss: 0.0059 \t Validation loss: 0.8041 \t QWK: 0.6371\n",
            "Step: 122    \t Train loss: 0.0235 \t Validation loss: 0.8176 \t QWK: 0.6216\n",
            "Step: 244    \t Train loss: 0.0486 \t Validation loss: 0.8225 \t QWK: 0.6371\n",
            "Epoch: 26    \t Test  loss: 0.8225 \t QWK: 0.6224\n",
            "Step: 0      \t Train loss: 0.0177 \t Validation loss: 0.8224 \t QWK: 0.6169\n",
            "Step: 122    \t Train loss: 0.0382 \t Validation loss: 0.8469 \t QWK: 0.6281\n",
            "Step: 244    \t Train loss: 0.0330 \t Validation loss: 0.8073 \t QWK: 0.6376\n",
            "Epoch: 27    \t Test  loss: 0.8198 \t QWK: 0.6198\n",
            "Step: 0      \t Train loss: 0.1508 \t Validation loss: 0.8211 \t QWK: 0.6198\n",
            "Step: 122    \t Train loss: 0.0312 \t Validation loss: 0.9095 \t QWK: 0.6078\n",
            "Step: 244    \t Train loss: 0.0309 \t Validation loss: 0.8465 \t QWK: 0.6245\n",
            "Epoch: 28    \t Test  loss: 0.8365 \t QWK: 0.6049\n",
            "Step: 0      \t Train loss: 0.0073 \t Validation loss: 0.8381 \t QWK: 0.6049\n",
            "Step: 122    \t Train loss: 0.0347 \t Validation loss: 0.8468 \t QWK: 0.6200\n",
            "Step: 244    \t Train loss: 0.0285 \t Validation loss: 0.8683 \t QWK: 0.6298\n",
            "Epoch: 29    \t Test  loss: 0.8162 \t QWK: 0.6312\n",
            "Step: 0      \t Train loss: 0.0071 \t Validation loss: 0.8164 \t QWK: 0.6312\n",
            "Step: 122    \t Train loss: 0.0242 \t Validation loss: 0.8313 \t QWK: 0.6196\n",
            "Step: 244    \t Train loss: 0.0381 \t Validation loss: 0.8232 \t QWK: 0.6034\n",
            "Epoch: 30    \t Test  loss: 0.8241 \t QWK: 0.6034\n",
            "Log file closed.\n"
          ]
        }
      ],
      "source": [
        "                                                                                                                                        # Start logging to a file\n",
        "fp = open_log_file(log_folder, essay_df, model, label_column=target_column, hyper_parameters=hp)\n",
        "\n",
        "try:\n",
        "    # Start training\n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "    model.train()\n",
        "    with accelerator.autocast():\n",
        "        fp.write(\"Training logs: \\n\\n\")\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss = train_loop(model, train_loader, val_loader, loss_fct, optimizer, lr_scheduler, progress_bar, fp, logging_step=len(train_loader)//3, use_amp=hp['use_amp'])\n",
        "            with torch.no_grad():\n",
        "                test_loss, test_preds, qwk = test_loop(model, test_loader, loss_fct)\n",
        "                log_string = \"Epoch: {:<6}\\t Test  loss: {:<6.4f} \\t QWK: {:<6.4f}\".format(epoch+1, test_loss, qwk)\n",
        "                print(log_string)\n",
        "                fp.write(log_string + \"\\n\")\n",
        "finally:\n",
        "    print(\"Log file closed.\")\n",
        "    fp.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05d98d9a7bc344fab5e22218b13714b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb46eba0c8f04dd08398f2cb19c49918",
              "IPY_MODEL_8a50b975788140fd9074bb1ad1cedee4",
              "IPY_MODEL_3085142b83644827a86888d924e30de7"
            ],
            "layout": "IPY_MODEL_0f5bec4f8fc646c08ab4199309bea7ca"
          }
        },
        "bb46eba0c8f04dd08398f2cb19c49918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ff7d074c214e7da6ea794f74ea5c65",
            "placeholder": "​",
            "style": "IPY_MODEL_394fd096a43749e5a0b3fe68558944fd",
            "value": "100%"
          }
        },
        "8a50b975788140fd9074bb1ad1cedee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc8b72ba4cb488a9bbd41941c02b190",
            "max": 10980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0f3c70b6426400484c7ae49f00c8d41",
            "value": 10980
          }
        },
        "3085142b83644827a86888d924e30de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c43e85af2654e29a905771294ab34f5",
            "placeholder": "​",
            "style": "IPY_MODEL_6f50380f96584ebc95816de70b140f3d",
            "value": " 10980/10980 [1:11:20&lt;00:00,  4.45it/s]"
          }
        },
        "0f5bec4f8fc646c08ab4199309bea7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ff7d074c214e7da6ea794f74ea5c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394fd096a43749e5a0b3fe68558944fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bc8b72ba4cb488a9bbd41941c02b190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f3c70b6426400484c7ae49f00c8d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c43e85af2654e29a905771294ab34f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f50380f96584ebc95816de70b140f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}